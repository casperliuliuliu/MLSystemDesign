{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn\n",
    "from datetime import datetime\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "import scipy.io\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"D:\\\\Casper\\\\OTHER\\\\Data\\\\identification code_database\\\\train.mat\"\n",
    "def load_data(path):\n",
    "    data = scipy.io.loadmat(path) \n",
    "    print(data.keys())\n",
    " \n",
    "    origin_X = np.array(data['x'].flat)\n",
    "    origin_Y = data['y'][0].reshape(5000,-1)\n",
    "    origin_Y_onehot= data['y_onehot'].reshape(5000,4,19)\n",
    "    \n",
    "    print (\"origin_X shape: \"+str(origin_X.shape))\n",
    "    print (\"origin_Y shape: \"+str(origin_Y.shape))\n",
    "    print (\"origin_Y_onehot shape: \"+str(origin_Y_onehot.shape))\n",
    " \n",
    "    return origin_X,origin_Y,origin_Y_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_img (o_data,write,save):  \n",
    "    index=0\n",
    "    p_data=[]\n",
    "    for i in o_data:\n",
    "        name='resize_data_image/resize_x_'+str(index)+'.jpg'\n",
    "        img = Image.fromarray(i, 'RGB')\n",
    "        img=img.resize((130,50))\n",
    "        if os.path.isfile(name) and save:      \n",
    "            print (name+\" is existed\")    \n",
    "        elif save:\n",
    "            img.save(name)\n",
    "        if write:\n",
    "            p_data.append(np.array(img))       \n",
    "        index+=1\n",
    "        \n",
    "    p_data=np.array(p_data)   \n",
    "    print (p_data.shape)\n",
    "    return p_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'y_onehot', 'x', 'y'])\n",
      "origin_X shape: (5000,)\n",
      "origin_Y shape: (5000, 4)\n",
      "origin_Y_onehot shape: (5000, 4, 19)\n",
      "(5000, 50, 130, 3)\n"
     ]
    }
   ],
   "source": [
    "origin_X,origin_Y,origin_Y_onehot=load_data(path)\n",
    "\n",
    "train_rate=0.5 #change to 0.9\n",
    "num_train_data=int(5000*train_rate)\n",
    "resize_x= resize_img(origin_X,True,False)\n",
    "train_x_orig=resize_x.reshape(5000,50,130,-1)[0:num_train_data]\n",
    "test_x_orig=resize_x.reshape(5000,50,130,-1)[num_train_data:]\n",
    "\n",
    "x_train=train_x_orig.astype('float32')/255\n",
    "x_test=test_x_orig.astype('float32')/255\n",
    "\n",
    "y_train_onehot=origin_Y_onehot[0:num_train_data]\n",
    "y_test_onehot=origin_Y_onehot[num_train_data:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_X_tensor = torch.tensor(x_train, dtype=torch.float32)\n",
    "origin_Y_tensor = torch.tensor(y_train_onehot, dtype=torch.float32)\n",
    "origin_Y_onehot_tensor = torch.tensor(y_train_onehot, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 130, 3])\n",
      "torch.Size([50, 130, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x26ae280bd60>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(origin_X_tensor[0].shape)\n",
    "tensor = origin_X_tensor[0].permute(2, 0, 1)\n",
    "tensor = tensor.permute(1, 2, 0)\n",
    "print(tensor.shape)\n",
    "# if tensor.min() < 0 or tensor.max() > 1:\n",
    "    # tensor = (tensor - tensor.min()) / (tensor.max() - tensor.min())\n",
    "\n",
    "plt.imshow(tensor)\n",
    "\n",
    "# print(origin_Y_onehot_tensor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision import datasets, transforms\n",
    "\n",
    "# transform = transforms.Compose([transforms.ToTensor(),\n",
    "#                                     transforms.Normalize((0.5,), (0.5,))])\n",
    "# train_loader = torch.utils.data.DataLoader(origin_X_tensor, batch_size=256, shuffle=True)\n",
    "# test_loader = torch.utils.data.DataLoader(origin_Y_onehot_tensor, batch_size=256, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_X_tensor_permuted = origin_X_tensor.permute(0, 3, 1, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class SimpleCharCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCharCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=5, padding=2)  # Assuming grayscale images\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, padding=2)\n",
    "        self.fc1 = nn.Linear(24576, 512)  # Adjust the size according to your image size\n",
    "        self.fc2 = nn.Linear(512, 76)  # 4 characters, each 26 possible letters\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2500, 76])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:09<01:21,  9.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "         0.]])\n",
      "tensor([[ 0.0099, -0.0881, -0.0607,  0.0250, -0.0140, -0.0618, -0.0254,  0.0498,\n",
      "          0.0320,  0.0391,  0.0180, -0.0144,  0.0096, -0.0481, -0.0020,  0.0269,\n",
      "         -0.0673,  0.0303,  0.0589],\n",
      "        [ 0.0014,  0.0603,  0.0410, -0.0960, -0.0172,  0.0226, -0.0698,  0.0563,\n",
      "         -0.0006, -0.0190,  0.0508, -0.0022, -0.0187,  0.0365,  0.0418,  0.0499,\n",
      "          0.0152, -0.0171,  0.0388],\n",
      "        [-0.0110,  0.0332,  0.0221,  0.1109,  0.0058,  0.0280,  0.0551,  0.0010,\n",
      "          0.0428,  0.0101, -0.0516, -0.0217, -0.0463,  0.0553,  0.0307, -0.0404,\n",
      "         -0.1053,  0.0348, -0.0596],\n",
      "        [ 0.0279, -0.0621, -0.0437,  0.0306,  0.0221, -0.0211,  0.0395,  0.0016,\n",
      "         -0.0155,  0.0315, -0.1224,  0.0350,  0.0366,  0.0839,  0.0297, -0.0130,\n",
      "         -0.0312,  0.0477, -0.0596]], grad_fn=<SelectBackward0>)\n",
      "Epoch 1, Loss: 0.694842517375946, Validation Loss: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:17<01:09,  8.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "         0.]])\n",
      "tensor([[-4.7692, -4.6888, -2.2989, -0.3953, -1.4256, -1.9215, -2.1624, -1.9115,\n",
      "         -0.6076, -1.3336, -2.7223, -3.5639, -2.3976, -2.6544, -0.9100, -1.9054,\n",
      "         -1.8816, -2.6544, -0.0337],\n",
      "        [-3.5408, -2.3447,  0.0070, -3.1055, -2.1194, -2.1010, -1.9620, -2.8019,\n",
      "         -2.6445, -2.3176, -2.1901, -1.4707,  0.1255, -0.7319, -2.8295, -1.7648,\n",
      "         -1.7926, -1.4834,  0.4218],\n",
      "        [-2.1155, -0.9138, -0.5452, -0.1679, -1.0392, -2.8222, -2.6157, -2.5781,\n",
      "         -0.8158, -2.7234, -1.2755, -0.9890, -4.0825, -2.4850, -0.7782, -2.1491,\n",
      "         -2.8648, -3.1697, -3.1591],\n",
      "        [-2.6153, -3.2511, -2.6948, -1.9008, -0.1996, -3.0378, -2.1354, -1.0586,\n",
      "         -1.9330, -1.4152, -2.7230, -1.7710, -1.7625, -1.6224, -1.9836, -1.9882,\n",
      "         -1.4764, -2.2526, -1.9179]], grad_fn=<SelectBackward0>)\n",
      "Epoch 2, Loss: 0.2958027124404907, Validation Loss: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:26<01:02,  8.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "         0.]])\n",
      "tensor([[-10.1097,  -8.5935,  -6.6800,  -4.3659,  -6.4850,  -5.7932,  -7.5974,\n",
      "          -6.7885,  -5.2743,  -6.2620,  -4.9084,  -5.2576,  -6.1751,  -6.7690,\n",
      "          -5.9960,  -4.5956,  -7.7105,  -6.2424,  -4.4710],\n",
      "        [ -7.9477,  -6.9250,  -4.3441,  -7.1352,  -5.4828,  -5.5693,  -4.5302,\n",
      "          -4.4340,  -7.7172,  -6.9676,  -6.8176,  -5.8774,  -3.9186,  -5.1294,\n",
      "          -6.3529,  -6.0367,  -7.1209,  -5.0707,  -3.1355],\n",
      "        [ -5.6015,  -4.4204,  -2.4923,  -5.6197,  -4.5038,  -6.2654,  -6.4100,\n",
      "          -7.6144,  -5.7765,  -6.6619,  -4.6314,  -5.9613,  -8.1921,  -6.8861,\n",
      "          -4.9529,  -5.5646,  -5.1757,  -5.2730,  -5.4949],\n",
      "        [ -4.6894,  -5.5266,  -7.8417,  -5.3494,  -3.8999,  -4.6892,  -4.9874,\n",
      "          -4.7156,  -3.7788,  -5.0186,  -8.4238,  -5.6275,  -5.4456,  -3.6618,\n",
      "          -4.4629,  -6.3164,  -5.9127,  -7.7454,  -7.5455]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Epoch 3, Loss: 0.3154533803462982, Validation Loss: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:35<00:53,  8.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "         0.]])\n",
      "tensor([[-7.5878, -5.3465, -5.2600, -4.9788, -6.1092, -4.4239, -6.2887, -6.0122,\n",
      "         -5.8544, -6.2597, -2.5362, -3.0626, -4.6661, -5.0578, -5.7839, -3.3165,\n",
      "         -5.8731, -3.6578, -5.5262],\n",
      "        [-5.8719, -5.9291, -5.8907, -5.0411, -3.9740, -4.0099, -2.7954, -1.6841,\n",
      "         -5.8363, -5.8404, -5.2269, -5.4209, -4.4760, -5.8350, -4.0750, -4.9272,\n",
      "         -5.8001, -3.9503, -4.3325],\n",
      "        [-3.4471, -5.1323, -3.6206, -6.1952, -4.1781, -4.3380, -4.3808, -5.8097,\n",
      "         -5.6528, -4.2893, -3.1416, -6.1458, -6.1000, -5.6957, -5.3613, -4.0469,\n",
      "         -2.7436, -2.9400, -3.5833],\n",
      "        [-2.6012, -3.1724, -5.7367, -4.4600, -5.0523, -2.1709, -2.9582, -4.0541,\n",
      "         -2.4531, -4.0316, -6.2851, -4.4547, -4.8099, -2.9927, -3.5374, -5.3718,\n",
      "         -5.1414, -5.8600, -6.4345]], grad_fn=<SelectBackward0>)\n",
      "Epoch 4, Loss: 0.26611435413360596, Validation Loss: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:44<00:44,  8.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "         0.]])\n",
      "tensor([[-4.3179, -2.6334, -3.1622, -3.8601, -4.0191, -2.6853, -3.8650, -3.9502,\n",
      "         -4.5239, -4.5957, -1.2174, -1.8029, -2.7614, -2.7102, -4.1556, -2.0937,\n",
      "         -3.7033, -1.3996, -4.4351],\n",
      "        [-3.3367, -3.9487, -4.9690, -2.7357, -2.3022, -2.4039, -1.9969, -1.7242,\n",
      "         -3.3643, -3.5736, -3.1427, -3.6847, -3.8752, -4.7607, -1.8837, -3.0455,\n",
      "         -3.6411, -2.3400, -3.6546],\n",
      "        [-1.7102, -4.0523, -3.1493, -4.8768, -2.8779, -2.5640, -2.3788, -3.4920,\n",
      "         -3.9049, -2.0728, -1.8400, -4.4751, -3.7211, -3.8122, -4.2164, -2.4779,\n",
      "         -1.1715, -1.4498, -1.7331],\n",
      "        [-1.7257, -1.8191, -3.1821, -2.9514, -4.2572, -1.1889, -1.8209, -2.5565,\n",
      "         -2.0864, -2.4659, -3.7040, -2.8818, -3.0682, -2.1669, -2.4039, -3.3459,\n",
      "         -3.2538, -3.5279, -3.9316]], grad_fn=<SelectBackward0>)\n",
      "Epoch 5, Loss: 0.22870343923568726, Validation Loss: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:53<00:35,  8.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "         0.]])\n",
      "tensor([[-2.3467, -1.6355, -1.6994, -2.8792, -2.3459, -1.5579, -2.3467, -2.5332,\n",
      "         -3.2998, -2.9366, -1.3359, -1.7983, -1.9048, -1.5543, -3.0120, -1.6341,\n",
      "         -2.4716, -1.2380, -3.3057],\n",
      "        [-1.9664, -2.4536, -3.6283, -1.5184, -1.7123, -1.5455, -1.8760, -1.9897,\n",
      "         -1.5884, -2.1238, -1.9037, -2.3756, -3.0838, -3.6514, -1.3545, -1.7246,\n",
      "         -2.2542, -1.5105, -2.8756],\n",
      "        [-1.4629, -2.9721, -2.4306, -3.6188, -2.0226, -1.5928, -1.3973, -1.9443,\n",
      "         -2.5241, -1.5017, -1.5720, -3.0549, -2.3015, -2.4190, -3.0322, -1.8623,\n",
      "         -1.1651, -1.4888, -1.1839],\n",
      "        [-1.6358, -1.6655, -1.7690, -2.0249, -3.1742, -1.3696, -1.7216, -1.8714,\n",
      "         -2.1428, -1.9816, -2.1676, -1.9342, -1.8631, -1.9303, -1.7661, -1.8423,\n",
      "         -2.0677, -2.0608, -2.0993]], grad_fn=<SelectBackward0>)\n",
      "Epoch 6, Loss: 0.2400507628917694, Validation Loss: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [01:02<00:27,  9.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "         0.]])\n",
      "tensor([[-1.8235, -1.9659, -1.5012, -2.7395, -1.9379, -1.6128, -1.9825, -2.2556,\n",
      "         -3.1008, -2.3668, -1.9698, -2.5058, -2.0385, -1.7502, -2.9993, -1.8478,\n",
      "         -2.1160, -1.7052, -3.1257],\n",
      "        [-1.8413, -2.0541, -3.4057, -1.4971, -2.0050, -1.6871, -2.1336, -2.6901,\n",
      "         -1.1390, -2.0203, -1.7535, -2.2211, -3.1248, -3.4965, -1.7076, -1.6027,\n",
      "         -1.8078, -1.6601, -2.9412],\n",
      "        [-1.8763, -2.7545, -2.5232, -3.5175, -2.0999, -1.6782, -1.5096, -1.6452,\n",
      "         -2.2880, -2.0224, -1.9662, -2.7767, -2.0559, -2.0598, -2.8125, -2.0717,\n",
      "         -1.7613, -2.1150, -1.5305],\n",
      "        [-2.1854, -2.0627, -1.6610, -2.1774, -2.9864, -2.0649, -2.1033, -2.1811,\n",
      "         -2.8299, -2.3666, -1.9055, -1.9442, -1.7757, -2.4821, -1.8600, -1.6236,\n",
      "         -1.8354, -1.7831, -1.5667]], grad_fn=<SelectBackward0>)\n",
      "Epoch 7, Loss: 0.23245549201965332, Validation Loss: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [01:11<00:17,  8.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "         0.]])\n",
      "tensor([[-2.0483, -2.8674, -1.9413, -3.3828, -2.1292, -2.2913, -2.3211, -2.6413,\n",
      "         -3.4760, -2.4155, -3.0878, -3.7575, -2.6739, -2.4855, -3.4654, -2.7370,\n",
      "         -2.3074, -2.7263, -3.5338],\n",
      "        [-2.2479, -2.2354, -3.7966, -2.1399, -2.7173, -2.2795, -2.8517, -3.8337,\n",
      "         -1.4380, -2.5653, -2.1620, -2.5832, -3.6361, -3.8429, -2.5754, -2.1370,\n",
      "         -2.0703, -2.3494, -3.4834],\n",
      "        [-2.7610, -3.1323, -3.1248, -4.0226, -2.7301, -2.1340, -2.0297, -2.0155,\n",
      "         -2.6241, -3.0586, -3.0170, -3.2688, -2.3229, -2.4343, -3.1122, -2.8810,\n",
      "         -2.6595, -3.0733, -2.3308],\n",
      "        [-3.1378, -2.9558, -2.2824, -2.7660, -3.3487, -3.2427, -2.9530, -3.0167,\n",
      "         -4.1240, -3.1415, -2.1529, -2.5449, -2.2680, -3.4844, -2.4663, -2.1552,\n",
      "         -2.2405, -2.1289, -1.9012]], grad_fn=<SelectBackward0>)\n",
      "Epoch 8, Loss: 0.21405798196792603, Validation Loss: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [01:20<00:09,  9.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "         0.]])\n",
      "tensor([[-2.5533, -3.7978, -2.7593, -4.0605, -2.6237, -3.2073, -2.7844, -3.1093,\n",
      "         -3.8300, -2.5474, -4.2462, -5.0371, -3.3770, -3.4465, -3.9401, -3.6837,\n",
      "         -2.4920, -3.7679, -4.0364],\n",
      "        [-2.8150, -2.6700, -4.2880, -3.1112, -3.4958, -3.1428, -3.5682, -4.9522,\n",
      "         -2.1405, -3.2721, -2.7752, -3.1331, -4.1768, -4.1762, -3.4974, -2.9130,\n",
      "         -2.5111, -3.2016, -4.0639],\n",
      "        [-3.7997, -3.4668, -3.7589, -4.5292, -3.4448, -2.8641, -2.8315, -2.6754,\n",
      "         -3.1219, -4.2471, -4.0802, -3.7923, -2.7186, -3.0148, -3.4998, -3.6889,\n",
      "         -3.6498, -4.1250, -3.4229],\n",
      "        [-4.1727, -3.8828, -3.1266, -3.4707, -3.7772, -4.5889, -3.8038, -3.9269,\n",
      "         -5.3832, -3.9688, -2.6234, -3.4022, -2.9906, -4.5148, -3.1732, -2.9954,\n",
      "         -2.8056, -2.5315, -2.6104]], grad_fn=<SelectBackward0>)\n",
      "Epoch 9, Loss: 0.2191227227449417, Validation Loss: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:29<00:00,  8.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "         0.]])\n",
      "tensor([[-2.8988, -4.2361, -3.3958, -4.2948, -2.9682, -3.8083, -3.0209, -3.2831,\n",
      "         -3.7746, -2.6056, -4.8318, -5.6605, -3.6885, -4.0004, -3.9674, -4.1438,\n",
      "         -2.5130, -4.2864, -4.1410],\n",
      "        [-3.1368, -2.9753, -4.3824, -3.8572, -3.8573, -3.7659, -3.8353, -5.4857,\n",
      "         -2.8669, -3.6750, -3.1486, -3.3994, -4.2805, -4.0429, -3.9945, -3.4825,\n",
      "         -2.8239, -3.6853, -4.1946],\n",
      "        [-4.3468, -3.4633, -3.9743, -4.5865, -3.7495, -3.3603, -3.4235, -3.1442,\n",
      "         -3.3181, -4.9301, -4.6421, -3.9225, -2.9603, -3.4073, -3.5642, -3.9576,\n",
      "         -4.2354, -4.6792, -4.1977],\n",
      "        [-4.6225, -4.3416, -3.6575, -3.7890, -3.8035, -5.3782, -4.1527, -4.3831,\n",
      "         -5.9400, -4.2626, -2.9061, -3.9307, -3.4512, -4.9671, -3.5819, -3.5674,\n",
      "         -3.2074, -2.7282, -3.2151]], grad_fn=<SelectBackward0>)\n",
      "Epoch 10, Loss: 0.22861023247241974, Validation Loss: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Split your data into training and validation sets\n",
    "# For demonstration, let's assume origin_X_tensor and origin_Y_onehot_tensor are available\n",
    "# and split manually for simplicity. Consider using `torch.utils.data.Dataset` and `DataLoader` for better handling.\n",
    "from tqdm import tqdm\n",
    "num_train = int(0.8 * len(origin_X_tensor))  # 80% for training\n",
    "train_X = origin_X_tensor_permuted\n",
    "train_Y = origin_Y_onehot_tensor.reshape(2500,-1)\n",
    "print(train_Y.shape)\n",
    "val_X = origin_X_tensor[num_train:]\n",
    "val_Y = origin_Y_onehot_tensor[num_train:]\n",
    "\n",
    "# Initialize the model, criterion, and optimizer\n",
    "model = SimpleCharCNN()\n",
    "criterion = nn.BCEWithLogitsLoss()  # Suitable for multi-label classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "epochs = 10\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(train_X)\n",
    "    loss = criterion(output, train_Y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(train_Y.reshape(2500, 4, -1)[0])\n",
    "    print(output.reshape(2500, 4, -1)[0])\n",
    "    # Validation\n",
    "    # model.eval()\n",
    "    # with torch.no_grad():\n",
    "    #     val_output = model(val_X)\n",
    "    #     val_loss = criterion(val_output, val_Y)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}, Validation Loss: \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'y_onehot', 'x', 'y'])\n",
      "[[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;66;03m# return 0, 0, 0\u001b[39;00m\n\u001b[0;32m     25\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mCasper\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mOTHER\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mData\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124midentification code_database\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mtrain.mat\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 26\u001b[0m origin_X, origin_Y, origin_Y_onehot \u001b[38;5;241m=\u001b[39m \u001b[43mload_data_torch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[31], line 15\u001b[0m, in \u001b[0;36mload_data_torch\u001b[1;34m(data_path)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(origin_Y_onehot[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Convert to PyTorch tensors\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m origin_X_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43morigin_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m origin_Y_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(origin_Y, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     17\u001b[0m origin_Y_onehot_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(origin_Y_onehot, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "\n",
    "def load_data_torch(data_path):\n",
    "    # Load the MATLAB file\n",
    "    data = scipy.io.loadmat(data_path)\n",
    "    print(data.keys())\n",
    "    # print(data['y'].shape)\n",
    "    # print(data['x'][0])\n",
    "    origin_X = np.array(data['x'].flat)  # Example for uniform shape. Adjust based on actual data structure\n",
    "    origin_Y = np.array(data['y'][0].reshape(5000, -1))\n",
    "    origin_Y_onehot = np.array(data['y_onehot'].reshape(5000, 4, 19))\n",
    "    print(origin_Y_onehot[0])\n",
    "\n",
    "    \n",
    "\n",
    "    print (\"x_train shape: \"+str(x_train.shape))\n",
    "    print (\"x_test shape: \"+str(x_test.shape))\n",
    "\n",
    "    y_train_onehot=origin_Y_onehot[0:num_train_data]\n",
    "    y_test_onehot=origin_Y_onehot[num_train_data:]\n",
    "\n",
    "    print (\"y_train_onehot shape: \"+str(y_train_onehot.shape))\n",
    "    print (\"y_test_onehot shape: \"+str(y_test_onehot.shape))\n",
    "    # Convert to PyTorch tensors\n",
    "    origin_X_tensor = torch.tensor(origin_X, dtype=torch.float32)\n",
    "    origin_Y_tensor = torch.tensor(origin_Y, dtype=torch.float32)\n",
    "    origin_Y_onehot_tensor = torch.tensor(origin_Y_onehot, dtype=torch.float32)\n",
    "    \n",
    "    print(\"origin_X_tensor shape: \"+str(origin_X_tensor.shape))\n",
    "    print(\"origin_Y_tensor shape: \"+str(origin_Y_tensor.shape))\n",
    "    print(\"origin_Y_onehot_tensor shape: \"+str(origin_Y_onehot_tensor.shape))\n",
    "\n",
    "    return origin_X_tensor, origin_Y_tensor, origin_Y_onehot_tensor\n",
    "    # return 0, 0, 0\n",
    "origin_X, origin_Y, origin_Y_onehot = load_data_torch(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "def load_original_data_pytorch(path):\n",
    "    # Define a transform to normalize the data\n",
    "    transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.5,), (0.5,))])\n",
    "    \n",
    "    # Download and load the training data\n",
    "    trainset = datasets.MNIST(path, download=True, train=True, transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=256, shuffle=True)\n",
    "\n",
    "    # Download and load the test data\n",
    "    testset = datasets.MNIST(path, download=True, train=False, transform=transform)\n",
    "    test_loader = torch.utils.data.DataLoader(testset, batch_size=256, shuffle=True)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "path = 'D:\\\\Casper\\\\OTHER\\\\Data\\\\MNIST_data'\n",
    "train_loader, test_loader = load_original_data_pytorch(path)\n",
    "loaders = {\n",
    "    'train': train_loader,\n",
    "    'test': test_loader\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build function\n"
     ]
    }
   ],
   "source": [
    "def pprint(output = '\\n', show_time = False): # print and fprint at the same time\n",
    "    filename = \"hw2-1.txt\"\n",
    "    print(output)\n",
    "    with open(filename, 'a') as f:\n",
    "        if show_time:\n",
    "            f.write(datetime.now().strftime(\"[%Y-%m-%d %H:%M:%S] \"))\n",
    "\n",
    "        f.write(str(output))\n",
    "        f.write('\\n')\n",
    "pprint(\"build function\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    total_num = 0\n",
    "\n",
    "    for parameter in model.parameters():\n",
    "        if parameter.requires_grad:\n",
    "            total_num += parameter.numel() \n",
    "    return total_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torchvision.models as models\n",
    "from torch import nn, optim\n",
    "from tqdm import tqdm\n",
    "def train(model, model_name):\n",
    "    pprint(f\"test {model_name}\", True)\n",
    "    model_parameters_amount = count_parameters(model)\n",
    "    pprint(f\"model total parameters: {model_parameters_amount:,}\")\n",
    "\n",
    "    model = model.cuda()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    lr= 0.005\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    pprint(f\"learning rate={lr}\")\n",
    "    iteration = 0\n",
    "    epochs = 20\n",
    "    start = time.time()\n",
    "    phases = ['train', 'test']\n",
    "    for epoch in range(epochs):\n",
    "        for phase in phases:\n",
    "            running_loss = 0.0\n",
    "            correct_predictions = 0\n",
    "            correct_top3_predictions = 0\n",
    "            total_samples = 0\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "            for images, labels in tqdm(loaders[phase]): # Iterate over data.\n",
    "                images, labels = images.cuda(), labels.cuda()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    if phase == 'train': # backward + optimize only if in training phase\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "\n",
    "                # Convert outputs to predicted class by selecting the class with the highest score\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                # Accumulate the number of correct predictions\n",
    "                correct_predictions += (predicted == labels).sum().item()\n",
    "                \n",
    "                _, top3_preds = outputs.topk(3, 1, True, True)\n",
    "                correct_top3_predictions += sum([labels[i] in top3_preds[i] for i in range(labels.size(0))])\n",
    "\n",
    "                total_samples += labels.size(0)\n",
    "                iteration += 1\n",
    "                # if iteration % 20 == 0:\n",
    "                #     print(iteration)\n",
    "            avg_loss = running_loss / total_samples\n",
    "            top1_accuracy = correct_predictions / total_samples * 100\n",
    "            top3_accuracy = correct_top3_predictions / total_samples * 100\n",
    "            pprint(f\"Epoch [{epoch+1}/{epochs}], phase: {phase}, samples: {total_samples}, Loss: {avg_loss:.4f}, Top-1 Accuracy: {top1_accuracy:.2f}%, Top-3 Accuracy: {top3_accuracy:.2f}%\")\n",
    "    end = time.time()\n",
    "    duration = end - start\n",
    "    pprint(f\"Elapsed time: {duration} seconds\")\n",
    "    model_scripted = torch.jit.script(model) # Export to TorchScript\n",
    "    model_scripted.save(f'{model_name}.pt') # Save\n",
    "    pprint(f\"weight saved as: {model_name}.pt\")   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 128)  # First layer: 784 input features, 128 output features\n",
    "        self.fc2 = nn.Linear(128, 64)   # Second layer: 128 input features, 64 output features\n",
    "        self.fc3 = nn.Linear(64, 10)    # Final layer: 64 input features, 10 output features (digits 0-9)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)  # Flatten the input tensor\n",
    "        x = F.relu(self.fc1(x))  # Apply ReLU non-linearity after first layer\n",
    "        x = F.relu(self.fc2(x))  # Apply ReLU non-linearity after second layer\n",
    "        x = self.fc3(x)  # No non-linearity after final layer\n",
    "        return F.log_softmax(x, dim=1)  # Apply log-softmax to output for classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 64)  # The image size is reduced to 7x7 after pooling layers\n",
    "        self.fc2 = nn.Linear(64, 10)  # 10 output classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # Convolution -> ReLU -> Pooling\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # Convolution -> ReLU -> Pooling\n",
    "        x = torch.flatten(x, 1)  # Flatten\n",
    "        x = F.relu(self.fc1(x))  # Dense layer -> ReLU\n",
    "        x = self.fc2(x)  # Output layer\n",
    "        return F.log_softmax(x, dim=1)  # Log Softmax activation for the output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test SimpleNN\n",
      "model total parameters: 109,386\n",
      "learning rate=0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:12<00:00, 18.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], phase: train, samples: 60000, Loss: 0.0017, Top-1 Accuracy: 86.47%, Top-3 Accuracy: 96.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:02<00:00, 19.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], phase: test, samples: 10000, Loss: 0.0009, Top-1 Accuracy: 93.02%, Top-3 Accuracy: 99.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:12<00:00, 18.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], phase: train, samples: 60000, Loss: 0.0007, Top-1 Accuracy: 94.18%, Top-3 Accuracy: 99.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 21.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], phase: test, samples: 10000, Loss: 0.0006, Top-1 Accuracy: 95.15%, Top-3 Accuracy: 99.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:12<00:00, 19.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], phase: train, samples: 60000, Loss: 0.0006, Top-1 Accuracy: 95.53%, Top-3 Accuracy: 99.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 20.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], phase: test, samples: 10000, Loss: 0.0005, Top-1 Accuracy: 96.24%, Top-3 Accuracy: 99.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:12<00:00, 18.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], phase: train, samples: 60000, Loss: 0.0005, Top-1 Accuracy: 96.42%, Top-3 Accuracy: 99.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 20.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], phase: test, samples: 10000, Loss: 0.0006, Top-1 Accuracy: 95.94%, Top-3 Accuracy: 99.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:12<00:00, 18.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], phase: train, samples: 60000, Loss: 0.0004, Top-1 Accuracy: 96.60%, Top-3 Accuracy: 99.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:02<00:00, 19.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], phase: test, samples: 10000, Loss: 0.0006, Top-1 Accuracy: 95.55%, Top-3 Accuracy: 99.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:13<00:00, 17.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], phase: train, samples: 60000, Loss: 0.0004, Top-1 Accuracy: 97.05%, Top-3 Accuracy: 99.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 21.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], phase: test, samples: 10000, Loss: 0.0004, Top-1 Accuracy: 96.72%, Top-3 Accuracy: 99.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 165/235 [00:09<00:04, 17.37it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m model_name \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSimpleNN\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      7\u001b[0m ]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ii \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(model_name)):\n\u001b[1;32m----> 9\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mii\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m[\u001b[49m\u001b[43mii\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[27], line 29\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, model_name)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     28\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()   \u001b[38;5;66;03m# Set model to evaluate mode\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m tqdm(loaders[phase]): \u001b[38;5;66;03m# Iterate over data.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m     images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mcuda(), labels\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m     31\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(images)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\GPU\\lib\\site-packages\\tqdm\\std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1179\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1182\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1185\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\GPU\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\GPU\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\GPU\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\GPU\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\GPU\\lib\\site-packages\\torchvision\\datasets\\mnist.py:138\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Any, Any]:\n\u001b[0;32m    131\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;124;03m        index (int): Index\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m        tuple: (image, target) where target is index of the target class.\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 138\u001b[0m     img, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[index], \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtargets\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;66;03m# doing this so that it is consistent with all other datasets\u001b[39;00m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;66;03m# to return a PIL Image\u001b[39;00m\n\u001b[0;32m    142\u001b[0m     img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_list = [\n",
    "    SimpleNN(),\n",
    "    SimpleCNN(),\n",
    "]\n",
    "\n",
    "model_name = [\n",
    "    \"SimpleNN\",\n",
    "    \"SimpleCNN\",\n",
    "]\n",
    "for ii in range(len(model_name)):\n",
    "    train(model_list[ii], model_name[ii])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
