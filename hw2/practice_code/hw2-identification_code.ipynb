{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn\n",
    "from datetime import datetime\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "import scipy.io\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image \n",
    "import os\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"D:\\\\Casper\\\\OTHER\\\\Data\\\\identification code_database\\\\train.mat\"\n",
    "path2 = \"D:\\\\Casper\\\\OTHER\\\\Data\\\\identification code_database\\\\denoise_train2.mat\"\n",
    "def load_data(path_X, path_Y):\n",
    "    data = scipy.io.loadmat(path_X) \n",
    "    print(data.keys())\n",
    "\n",
    "    # origin_X = np.array(data['x'].flat)\n",
    "    origin_X = np.array(data['denoise2_x'])\n",
    "    data = scipy.io.loadmat(path_Y) \n",
    "    origin_Y = data['y'][0].reshape(5000,-1)\n",
    "    origin_Y_onehot= data['y_onehot'].reshape(5000,4,19)\n",
    "    \n",
    "    print (\"origin_X shape: \"+str(origin_X.shape))\n",
    "    print (\"origin_Y shape: \"+str(origin_Y.shape))\n",
    "    print (\"origin_Y_onehot shape: \"+str(origin_Y_onehot.shape))\n",
    " \n",
    "    return origin_X,origin_Y,origin_Y_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_img (o_data,write,save):  \n",
    "    index=0\n",
    "    p_data=[]\n",
    "    for i in o_data:\n",
    "        name='resize_data_image/resize_x_'+str(index)+'.jpg'\n",
    "        img = Image.fromarray(i, 'RGB')\n",
    "        img=img.resize((130,50))\n",
    "        if os.path.isfile(name) and save:      \n",
    "            print (name+\" is existed\")    \n",
    "        elif save:\n",
    "            img.save(name)\n",
    "        if write:\n",
    "            p_data.append(np.array(img))       \n",
    "        index+=1\n",
    "        \n",
    "    p_data=np.array(p_data)   \n",
    "    print (p_data.shape)\n",
    "    return p_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'denoise2_x'])\n",
      "origin_X shape: (5000, 50, 130)\n",
      "origin_Y shape: (5000, 4)\n",
      "origin_Y_onehot shape: (5000, 4, 19)\n",
      "(5000, 50, 130)\n"
     ]
    }
   ],
   "source": [
    "origin_X,origin_Y,origin_Y_onehot=load_data(path2, path)\n",
    "\n",
    "train_rate=0.5 #change to 0.9\n",
    "num_train_data=int(5000*train_rate)\n",
    "print(origin_X.shape)\n",
    "# resize_x= resize_img(origin_X,True,False)\n",
    "resize_x= origin_X\n",
    "train_x_orig=resize_x.reshape(5000,50,130,-1)[0:num_train_data]\n",
    "test_x_orig=resize_x.reshape(5000,50,130,-1)[num_train_data:]\n",
    "\n",
    "x_train=train_x_orig.astype('float32')/255\n",
    "x_test=test_x_orig.astype('float32')/255\n",
    "\n",
    "y_train_onehot=origin_Y_onehot[0:num_train_data]\n",
    "y_test_onehot=origin_Y_onehot[num_train_data:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_X_tensor = torch.tensor(x_train, dtype=torch.float32)\n",
    "origin_Y_tensor = torch.tensor(y_train_onehot, dtype=torch.float32)\n",
    "origin_Y_onehot_tensor = torch.tensor(y_train_onehot, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 130, 1])\n",
      "torch.Size([50, 130, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ff157d3190>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(origin_X_tensor[0].shape)\n",
    "tensor = origin_X_tensor[0].permute(2, 0, 1)\n",
    "tensor = tensor.permute(1, 2, 0)\n",
    "print(tensor.shape)\n",
    "# if tensor.min() < 0 or tensor.max() > 1:\n",
    "    # tensor = (tensor - tensor.min()) / (tensor.max() - tensor.min())\n",
    "\n",
    "plt.imshow(tensor)\n",
    "\n",
    "# print(origin_Y_onehot_tensor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision import datasets, transforms\n",
    "\n",
    "# transform = transforms.Compose([transforms.ToTensor(),\n",
    "#                                     transforms.Normalize((0.5,), (0.5,))])\n",
    "# train_loader = torch.utils.data.DataLoader(origin_X_tensor, batch_size=256, shuffle=True)\n",
    "# test_loader = torch.utils.data.DataLoader(origin_Y_onehot_tensor, batch_size=256, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_X_tensor_permuted = origin_X_tensor.permute(0, 3, 1, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class SimpleCharCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCharCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=5, padding=2)  # Assuming grayscale images\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, padding=2)\n",
    "        self.fc1 = nn.Linear(24576, 512)  # Adjust the size according to your image size\n",
    "        self.fc2 = nn.Linear(512, 76)  # 4 characters, each 26 possible letters\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleCharCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCharCNN, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv11_W1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=5, stride=1, padding='same')\n",
    "        self.conv12_W1 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1)\n",
    "        self.max_pool1_W1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv23_W1 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5, stride=1, padding='same')\n",
    "        self.conv24_W1 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1)\n",
    "        self.conv25_W1 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1)\n",
    "        self.bn1_W1 = nn.BatchNorm2d(128)\n",
    "        self.max_pool2_W1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv36_W1 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=1, stride=1, padding='same')\n",
    "        self.conv37_W1 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1)\n",
    "        self.conv38_W1 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1)\n",
    "        self.max_pool3_W1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv49_W1 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding='same')\n",
    "        self.conv410_W1 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=1, stride=1)\n",
    "        self.bn2_W1 = nn.BatchNorm2d(512)\n",
    "        self.max_pool4_W1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        # Dense (Fully Connected) Layers for each output branch\n",
    "        self.fc_branches = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(in_features=3072, out_features=128),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.25),\n",
    "                nn.Linear(in_features=128, out_features=128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(in_features=128, out_features=19),\n",
    "                nn.Softmax(dim=1)\n",
    "            ) for _ in range(4)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv11_W1(x))\n",
    "        x = F.relu(self.conv12_W1(x))\n",
    "        x = self.max_pool1_W1(x)\n",
    "        \n",
    "        x = F.relu(self.conv23_W1(x))\n",
    "        x = F.relu(self.conv24_W1(x))\n",
    "        x = F.relu(self.conv25_W1(x))\n",
    "        x = self.bn1_W1(x)\n",
    "        x = self.max_pool2_W1(x)\n",
    "        \n",
    "        x = F.relu(self.conv36_W1(x))\n",
    "        x = F.relu(self.conv37_W1(x))\n",
    "        x = F.relu(self.conv38_W1(x))\n",
    "        x = self.max_pool3_W1(x)\n",
    "        \n",
    "        x = F.relu(self.conv49_W1(x))\n",
    "        x = F.relu(self.conv410_W1(x))\n",
    "        x = self.bn2_W1(x)\n",
    "        x = self.max_pool4_W1(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Branch out to the four different dense layers\n",
    "        outputs = torch.stack([branch(x) for branch in self.fc_branches], dim = 1)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2500, 1, 50, 130])\n",
      "torch.Size([2500, 76])\n"
     ]
    }
   ],
   "source": [
    "train_X = origin_X_tensor_permuted\n",
    "train_Y = origin_Y_onehot_tensor.reshape(2500,-1)\n",
    "print(train_X.shape)\n",
    "print(train_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split your data into training and validation sets\n",
    "# For demonstration, let's assume origin_X_tensor and origin_Y_onehot_tensor are available\n",
    "# and split manually for simplicity. Consider using `torch.utils.data.Dataset` and `DataLoader` for better handling.\n",
    "from tqdm import tqdm\n",
    "# num_train = int(0.8 * len(origin_X_tensor))  # 80% for training\n",
    "\n",
    "\n",
    "\n",
    "def train(model, epochs, batch_size, reshape=False):\n",
    "    # criterion = nn.BCEWithLogitsLoss()  # Suitable for multi-label classification\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.8, patience=5, verbose=True, min_lr=0)\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    train_Y_reshaped = train_Y.reshape(2500, 4, -1)\n",
    "    _, label = torch.max(train_Y_reshaped, 1)\n",
    "\n",
    "    model = model.cuda()\n",
    "    for epoch in range(epochs):\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "        running_loss = 0.0\n",
    "        model.train()\n",
    "\n",
    "        for i in tqdm(range(0, len(train_X), batch_size)):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Create a batch\n",
    "            batch_X = train_X[i:i+batch_size]\n",
    "            batch_Y = train_Y_reshaped[i:i+batch_size]\n",
    "            batch_labels = label[i:i+batch_size]\n",
    "            batch_X, batch_Y, batch_labels = batch_X.cuda(), batch_Y.cuda(), batch_labels.cuda()\n",
    "\n",
    "            # Forward pass\n",
    "            output = model(batch_X)\n",
    "            # print(output.shape)\n",
    "            # print(batch_Y.shape)\n",
    "            loss = criterion(output, batch_Y)\n",
    "\n",
    "            # Backward and optimize\n",
    "            loss.backward()\n",
    "            running_loss += loss.item()\n",
    "            optimizer.step()\n",
    "            # Calculate accuracy\n",
    "            if reshape:\n",
    "                output_reshaped = output.reshape(batch_Y.shape[0], 19, -1)\n",
    "            else:\n",
    "                output_reshaped = output\n",
    "            _, predicted = torch.max(output_reshaped, 1)\n",
    "            # print(predicted.shape)\n",
    "            # print(batch_labels.shape)\n",
    "            correct_predictions += (predicted == batch_labels).sum().item()\n",
    "            total_samples += batch_labels.size(0) * 19\n",
    "        scheduler.step(running_loss)\n",
    "\n",
    "        # Compute accuracy over all batches\n",
    "        top1_accuracy = correct_predictions / total_samples * 100\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item()}, Accuracy: {top1_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/79 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 52.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.2839244306087494, Accuracy: 24.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 63.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.26371631026268005, Accuracy: 28.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 64.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.2542389929294586, Accuracy: 26.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 63.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.262136310338974, Accuracy: 25.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 63.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.2470652461051941, Accuracy: 30.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 63.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.24263417720794678, Accuracy: 29.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 63.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.25369828939437866, Accuracy: 29.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 64.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.24103280901908875, Accuracy: 28.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 64.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.2357170730829239, Accuracy: 29.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 64.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.2204730361700058, Accuracy: 28.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 64.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 0.21473334729671478, Accuracy: 29.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 64.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss: 0.21340876817703247, Accuracy: 29.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 63.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss: 0.2128426879644394, Accuracy: 28.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 62.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Loss: 0.20878271758556366, Accuracy: 28.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 63.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Loss: 0.2110184133052826, Accuracy: 28.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 62.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Loss: 0.1919773817062378, Accuracy: 29.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 61.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Loss: 0.2263331115245819, Accuracy: 30.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 63.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Loss: 0.2008209377527237, Accuracy: 31.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 63.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Loss: 0.19143858551979065, Accuracy: 30.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 63.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Loss: 0.2043992429971695, Accuracy: 32.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 64.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Loss: 0.19442328810691833, Accuracy: 32.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 63.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Loss: 0.19640672206878662, Accuracy: 33.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 63.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, Loss: 0.19460567831993103, Accuracy: 33.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 63.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Loss: 0.194345623254776, Accuracy: 33.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 63.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Loss: 0.19492670893669128, Accuracy: 32.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 63.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, Loss: 0.18896743655204773, Accuracy: 33.29%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 63.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, Loss: 0.19631877541542053, Accuracy: 32.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 64.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, Loss: 0.1974382847547531, Accuracy: 31.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 64.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, Loss: 0.18897561728954315, Accuracy: 32.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 63.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Loss: 0.1939459592103958, Accuracy: 32.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 64.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, Loss: 0.19742704927921295, Accuracy: 33.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 63.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, Loss: 0.20584596693515778, Accuracy: 34.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 63.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, Loss: 0.20025993883609772, Accuracy: 34.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 64.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34, Loss: 0.19838501513004303, Accuracy: 33.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 63.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35, Loss: 0.20476287603378296, Accuracy: 34.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 64.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36, Loss: 0.2014731913805008, Accuracy: 34.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 63.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37, Loss: 0.18896712362766266, Accuracy: 35.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 64.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38, Loss: 0.19958214461803436, Accuracy: 36.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 64.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39, Loss: 0.196241557598114, Accuracy: 36.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 64.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Loss: 0.18896712362766266, Accuracy: 36.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 64.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41, Loss: 0.18896712362766266, Accuracy: 36.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 64.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42, Loss: 0.1891285926103592, Accuracy: 36.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 63.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, Loss: 0.18896718323230743, Accuracy: 36.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 64.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44, Loss: 0.18896712362766266, Accuracy: 37.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 63.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45, Loss: 0.18896880745887756, Accuracy: 36.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 64.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46, Loss: 0.18896745145320892, Accuracy: 37.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 63.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47, Loss: 0.18896712362766266, Accuracy: 37.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 63.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, Loss: 0.18903577327728271, Accuracy: 38.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 64.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49, Loss: 0.18896712362766266, Accuracy: 38.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 64.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Loss: 0.18896716833114624, Accuracy: 39.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = SimpleCharCNN()\n",
    "train(model, 50, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/79 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "0D or 1D target tensor expected, multi-target not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[187], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39mfc \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mLinear(num_features, \u001b[38;5;241m76\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# print(num_features)\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[181], line 40\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, epochs, batch_size, reshape)\u001b[0m\n\u001b[0;32m     37\u001b[0m output \u001b[38;5;241m=\u001b[39m model(batch_X)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# print(output.shape)\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# print(batch_Y.shape)\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_Y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Backward and optimize\u001b[39;00m\n\u001b[0;32m     43\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\GPU\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\GPU\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\GPU\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1179\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1180\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1181\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\GPU\\lib\\site-packages\\torch\\nn\\functional.py:3053\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3052\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: 0D or 1D target tensor expected, multi-target not supported"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "\n",
    "model = models.resnet152(weights = models.ResNet152_Weights.DEFAULT)\n",
    "# print(model)\n",
    "num_channel = model.conv1.in_channels\n",
    "model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = torch.nn.Linear(num_features, 76)\n",
    "# print(num_features)\n",
    "train(model, 50, 32, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCharCNN()\n",
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 19])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/79 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 42.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.2847995162010193, Accuracy: 114.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 47.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.2775733172893524, Accuracy: 144.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 47.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.2559804618358612, Accuracy: 136.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 47.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.2573447525501251, Accuracy: 143.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 33/79 [00:00<00:00, 46.49it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[129], line 80\u001b[0m\n\u001b[0;32m     78\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(input_tensor)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28mprint\u001b[39m(outputs\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 80\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[128], line 40\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, epochs, batch_size, reshape)\u001b[0m\n\u001b[0;32m     37\u001b[0m batch_X, batch_Y, batch_labels \u001b[38;5;241m=\u001b[39m batch_X\u001b[38;5;241m.\u001b[39mcuda(), batch_Y\u001b[38;5;241m.\u001b[39mcuda(), batch_labels\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_X\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# print(output.shape)\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# print(batch_Y.shape)\u001b[39;00m\n\u001b[0;32m     43\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, batch_Y)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\GPU\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\GPU\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[129], line 51\u001b[0m, in \u001b[0;36mSimpleCharCNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     48\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv12_W1(x))\n\u001b[0;32m     49\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_pool1_W1(x)\n\u001b[1;32m---> 51\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv23_W1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     52\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv24_W1(x))\n\u001b[0;32m     53\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv25_W1(x))\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\GPU\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\GPU\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\GPU\\lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\GPU\\lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train2(model, train_X, train_Y, epochs, batch_size):\n",
    "    # Assuming `train_Y` is a list of tensors for each output, each with shape [num_samples, num_classes]\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.8, patience=5, verbose=True, cooldown=0, min_lr=0)\n",
    "\n",
    "    model = model.cuda()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_predictions = [0 for _ in range(len(train_Y))]\n",
    "        total_samples = [0 for _ in range(len(train_Y))]\n",
    "\n",
    "        for i in tqdm(range(0, len(train_X), batch_size)):\n",
    "            batch_X = train_X[i:i+batch_size].cuda()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(batch_X)\n",
    "            \n",
    "            loss = 0\n",
    "            for j, output in enumerate(outputs):  # Iterate through each set of model outputs\n",
    "                batch_Y_j = train_Y[j][i:i+batch_size].cuda()\n",
    "                loss += criterion(output, torch.max(batch_Y_j, 1)[1])  # Assuming one-hot encoded labels\n",
    "                \n",
    "                # For accuracy calculation\n",
    "                _, predicted = torch.max(output, 1)\n",
    "                correct_predictions[j] += (predicted == torch.max(batch_Y_j, 1)[1]).sum().item()\n",
    "                total_samples[j] += batch_Y_j.size(0)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        scheduler.step(running_loss)\n",
    "\n",
    "        # Compute and print accuracy for each output\n",
    "        for j in range(len(correct_predictions)):\n",
    "            accuracy = 100 * correct_predictions[j] / total_samples[j]\n",
    "            print(f'Epoch {epoch+1}, Output {j+1}, Loss: {running_loss:.4f}, Accuracy: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/79 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[108], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m NUM_EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[0;32m      9\u001b[0m BATCH_SIZE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n\u001b[1;32m---> 10\u001b[0m \u001b[43mtrain2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_Y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[107], line 24\u001b[0m, in \u001b[0;36mtrain2\u001b[1;34m(model, train_X, train_Y, epochs, batch_size)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(outputs):  \u001b[38;5;66;03m# Iterate through each set of model outputs\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     batch_Y_j \u001b[38;5;241m=\u001b[39m train_Y[j][i:i\u001b[38;5;241m+\u001b[39mbatch_size]\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m---> 24\u001b[0m     loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m criterion(output, \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_Y_j\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m])  \u001b[38;5;66;03m# Assuming one-hot encoded labels\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;66;03m# For accuracy calculation\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(output, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "\n",
    "model = SimpleCharCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.8, patience=5, verbose=True, min_lr=0)\n",
    "\n",
    "# early_stopping = EarlyStopping(patience=15, verbose=True, path='model_checkpoint.pt')\n",
    "\n",
    "NUM_EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "train2(model,train_X, train_Y, NUM_EPOCHS, BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4848396"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    total_num = 0\n",
    "    for parameter in model.parameters():\n",
    "        if parameter.requires_grad:\n",
    "            total_num += parameter.numel() \n",
    "    return total_num\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2500, 4])\n",
      "torch.Size([2500, 4])\n",
      "tensor([[ 0,  0,  0, 10],\n",
      "        [ 0,  5,  0,  0],\n",
      "        [ 0,  0, 14, 10],\n",
      "        ...,\n",
      "        [ 5,  4, 18, 13],\n",
      "        [ 2,  6,  0, 17],\n",
      "        [ 6,  3,  0,  0]])\n",
      "307\n"
     ]
    }
   ],
   "source": [
    "# print(one_hot_output)\n",
    "output = output.reshape(2500, 19, -1)\n",
    "train_Y = train_Y.reshape(2500, 19, -1)\n",
    "_, label = torch.max(train_Y, 1)\n",
    "_, predicted = torch.max(output, 1)\n",
    "print(predicted.shape)\n",
    "print(label.shape)\n",
    "print(label)\n",
    "print((predicted == label).sum().item())\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'y_onehot', 'x', 'y'])\n",
      "[[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;66;03m# return 0, 0, 0\u001b[39;00m\n\u001b[0;32m     25\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mCasper\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mOTHER\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mData\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124midentification code_database\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mtrain.mat\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 26\u001b[0m origin_X, origin_Y, origin_Y_onehot \u001b[38;5;241m=\u001b[39m \u001b[43mload_data_torch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[31], line 15\u001b[0m, in \u001b[0;36mload_data_torch\u001b[1;34m(data_path)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(origin_Y_onehot[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Convert to PyTorch tensors\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m origin_X_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43morigin_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m origin_Y_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(origin_Y, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     17\u001b[0m origin_Y_onehot_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(origin_Y_onehot, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "\n",
    "def load_data_torch(data_path):\n",
    "    # Load the MATLAB file\n",
    "    data = scipy.io.loadmat(data_path)\n",
    "    print(data.keys())\n",
    "    # print(data['y'].shape)\n",
    "    # print(data['x'][0])\n",
    "    origin_X = np.array(data['x'].flat)  # Example for uniform shape. Adjust based on actual data structure\n",
    "    origin_Y = np.array(data['y'][0].reshape(5000, -1))\n",
    "    origin_Y_onehot = np.array(data['y_onehot'].reshape(5000, 4, 19))\n",
    "    print(origin_Y_onehot[0])\n",
    "\n",
    "    \n",
    "\n",
    "    print (\"x_train shape: \"+str(x_train.shape))\n",
    "    print (\"x_test shape: \"+str(x_test.shape))\n",
    "\n",
    "    y_train_onehot=origin_Y_onehot[0:num_train_data]\n",
    "    y_test_onehot=origin_Y_onehot[num_train_data:]\n",
    "\n",
    "    print (\"y_train_onehot shape: \"+str(y_train_onehot.shape))\n",
    "    print (\"y_test_onehot shape: \"+str(y_test_onehot.shape))\n",
    "    # Convert to PyTorch tensors\n",
    "    origin_X_tensor = torch.tensor(origin_X, dtype=torch.float32)\n",
    "    origin_Y_tensor = torch.tensor(origin_Y, dtype=torch.float32)\n",
    "    origin_Y_onehot_tensor = torch.tensor(origin_Y_onehot, dtype=torch.float32)\n",
    "    \n",
    "    print(\"origin_X_tensor shape: \"+str(origin_X_tensor.shape))\n",
    "    print(\"origin_Y_tensor shape: \"+str(origin_Y_tensor.shape))\n",
    "    print(\"origin_Y_onehot_tensor shape: \"+str(origin_Y_onehot_tensor.shape))\n",
    "\n",
    "    return origin_X_tensor, origin_Y_tensor, origin_Y_onehot_tensor\n",
    "    # return 0, 0, 0\n",
    "origin_X, origin_Y, origin_Y_onehot = load_data_torch(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "def load_original_data_pytorch(path):\n",
    "    # Define a transform to normalize the data\n",
    "    transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.5,), (0.5,))])\n",
    "    \n",
    "    # Download and load the training data\n",
    "    trainset = datasets.MNIST(path, download=True, train=True, transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=256, shuffle=True)\n",
    "\n",
    "    # Download and load the test data\n",
    "    testset = datasets.MNIST(path, download=True, train=False, transform=transform)\n",
    "    test_loader = torch.utils.data.DataLoader(testset, batch_size=256, shuffle=True)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "path = 'D:\\\\Casper\\\\OTHER\\\\Data\\\\MNIST_data'\n",
    "train_loader, test_loader = load_original_data_pytorch(path)\n",
    "loaders = {\n",
    "    'train': train_loader,\n",
    "    'test': test_loader\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build function\n"
     ]
    }
   ],
   "source": [
    "def pprint(output = '\\n', show_time = False): # print and fprint at the same time\n",
    "    filename = \"hw2-1.txt\"\n",
    "    print(output)\n",
    "    with open(filename, 'a') as f:\n",
    "        if show_time:\n",
    "            f.write(datetime.now().strftime(\"[%Y-%m-%d %H:%M:%S] \"))\n",
    "\n",
    "        f.write(str(output))\n",
    "        f.write('\\n')\n",
    "pprint(\"build function\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    total_num = 0\n",
    "\n",
    "    for parameter in model.parameters():\n",
    "        if parameter.requires_grad:\n",
    "            total_num += parameter.numel() \n",
    "    return total_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torchvision.models as models\n",
    "from torch import nn, optim\n",
    "from tqdm import tqdm\n",
    "def train(model, model_name):\n",
    "    pprint(f\"test {model_name}\", True)\n",
    "    model_parameters_amount = count_parameters(model)\n",
    "    pprint(f\"model total parameters: {model_parameters_amount:,}\")\n",
    "\n",
    "    model = model.cuda()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    lr= 0.005\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    pprint(f\"learning rate={lr}\")\n",
    "    iteration = 0\n",
    "    epochs = 20\n",
    "    start = time.time()\n",
    "    phases = ['train', 'test']\n",
    "    for epoch in range(epochs):\n",
    "        for phase in phases:\n",
    "            running_loss = 0.0\n",
    "            correct_predictions = 0\n",
    "            correct_top3_predictions = 0\n",
    "            total_samples = 0\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "            for images, labels in tqdm(loaders[phase]): # Iterate over data.\n",
    "                images, labels = images.cuda(), labels.cuda()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    if phase == 'train': # backward + optimize only if in training phase\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "\n",
    "                # Convert outputs to predicted class by selecting the class with the highest score\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                # Accumulate the number of correct predictions\n",
    "                correct_predictions += (predicted == labels).sum().item()\n",
    "                \n",
    "                _, top3_preds = outputs.topk(3, 1, True, True)\n",
    "                correct_top3_predictions += sum([labels[i] in top3_preds[i] for i in range(labels.size(0))])\n",
    "\n",
    "                total_samples += labels.size(0)\n",
    "                iteration += 1\n",
    "                # if iteration % 20 == 0:\n",
    "                #     print(iteration)\n",
    "            avg_loss = running_loss / total_samples\n",
    "            top1_accuracy = correct_predictions / total_samples * 100\n",
    "            top3_accuracy = correct_top3_predictions / total_samples * 100\n",
    "            pprint(f\"Epoch [{epoch+1}/{epochs}], phase: {phase}, samples: {total_samples}, Loss: {avg_loss:.4f}, Top-1 Accuracy: {top1_accuracy:.2f}%, Top-3 Accuracy: {top3_accuracy:.2f}%\")\n",
    "    end = time.time()\n",
    "    duration = end - start\n",
    "    pprint(f\"Elapsed time: {duration} seconds\")\n",
    "    model_scripted = torch.jit.script(model) # Export to TorchScript\n",
    "    model_scripted.save(f'{model_name}.pt') # Save\n",
    "    pprint(f\"weight saved as: {model_name}.pt\")   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 128)  # First layer: 784 input features, 128 output features\n",
    "        self.fc2 = nn.Linear(128, 64)   # Second layer: 128 input features, 64 output features\n",
    "        self.fc3 = nn.Linear(64, 10)    # Final layer: 64 input features, 10 output features (digits 0-9)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)  # Flatten the input tensor\n",
    "        x = F.relu(self.fc1(x))  # Apply ReLU non-linearity after first layer\n",
    "        x = F.relu(self.fc2(x))  # Apply ReLU non-linearity after second layer\n",
    "        x = self.fc3(x)  # No non-linearity after final layer\n",
    "        return F.log_softmax(x, dim=1)  # Apply log-softmax to output for classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 64)  # The image size is reduced to 7x7 after pooling layers\n",
    "        self.fc2 = nn.Linear(64, 10)  # 10 output classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # Convolution -> ReLU -> Pooling\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # Convolution -> ReLU -> Pooling\n",
    "        x = torch.flatten(x, 1)  # Flatten\n",
    "        x = F.relu(self.fc1(x))  # Dense layer -> ReLU\n",
    "        x = self.fc2(x)  # Output layer\n",
    "        return F.log_softmax(x, dim=1)  # Log Softmax activation for the output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test SimpleNN\n",
      "model total parameters: 109,386\n",
      "learning rate=0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:12<00:00, 18.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], phase: train, samples: 60000, Loss: 0.0017, Top-1 Accuracy: 86.47%, Top-3 Accuracy: 96.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:02<00:00, 19.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], phase: test, samples: 10000, Loss: 0.0009, Top-1 Accuracy: 93.02%, Top-3 Accuracy: 99.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:12<00:00, 18.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], phase: train, samples: 60000, Loss: 0.0007, Top-1 Accuracy: 94.18%, Top-3 Accuracy: 99.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 21.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], phase: test, samples: 10000, Loss: 0.0006, Top-1 Accuracy: 95.15%, Top-3 Accuracy: 99.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:12<00:00, 19.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], phase: train, samples: 60000, Loss: 0.0006, Top-1 Accuracy: 95.53%, Top-3 Accuracy: 99.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 20.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], phase: test, samples: 10000, Loss: 0.0005, Top-1 Accuracy: 96.24%, Top-3 Accuracy: 99.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:12<00:00, 18.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], phase: train, samples: 60000, Loss: 0.0005, Top-1 Accuracy: 96.42%, Top-3 Accuracy: 99.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 20.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], phase: test, samples: 10000, Loss: 0.0006, Top-1 Accuracy: 95.94%, Top-3 Accuracy: 99.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:12<00:00, 18.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], phase: train, samples: 60000, Loss: 0.0004, Top-1 Accuracy: 96.60%, Top-3 Accuracy: 99.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:02<00:00, 19.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], phase: test, samples: 10000, Loss: 0.0006, Top-1 Accuracy: 95.55%, Top-3 Accuracy: 99.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:13<00:00, 17.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], phase: train, samples: 60000, Loss: 0.0004, Top-1 Accuracy: 97.05%, Top-3 Accuracy: 99.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 21.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], phase: test, samples: 10000, Loss: 0.0004, Top-1 Accuracy: 96.72%, Top-3 Accuracy: 99.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 165/235 [00:09<00:04, 17.37it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m model_name \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSimpleNN\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      7\u001b[0m ]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ii \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(model_name)):\n\u001b[1;32m----> 9\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mii\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m[\u001b[49m\u001b[43mii\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[27], line 29\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, model_name)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     28\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()   \u001b[38;5;66;03m# Set model to evaluate mode\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m tqdm(loaders[phase]): \u001b[38;5;66;03m# Iterate over data.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m     images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mcuda(), labels\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m     31\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(images)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\GPU\\lib\\site-packages\\tqdm\\std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1179\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1182\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1185\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\GPU\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\GPU\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\GPU\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\GPU\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\GPU\\lib\\site-packages\\torchvision\\datasets\\mnist.py:138\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Any, Any]:\n\u001b[0;32m    131\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;124;03m        index (int): Index\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m        tuple: (image, target) where target is index of the target class.\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 138\u001b[0m     img, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[index], \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtargets\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;66;03m# doing this so that it is consistent with all other datasets\u001b[39;00m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;66;03m# to return a PIL Image\u001b[39;00m\n\u001b[0;32m    142\u001b[0m     img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_list = [\n",
    "    SimpleNN(),\n",
    "    SimpleCNN(),\n",
    "]\n",
    "\n",
    "model_name = [\n",
    "    \"SimpleNN\",\n",
    "    \"SimpleCNN\",\n",
    "]\n",
    "for ii in range(len(model_name)):\n",
    "    train(model_list[ii], model_name[ii])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
